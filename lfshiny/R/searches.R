# SEARCH FUNCTIONS

# Functions to generate URLs and call APIs

# Generics

#' Turn a search term into a dplyr filter condition
#' 
#' @param searchterm Search term (including AND, OR, NOT, quotes and brackets where required)
#' @import stringr
#' @import purrr
#' @import dplyr
#' @return A string to pass to a dplyr filter
#' 
search2filter <- function(searchterm) {
  
  terms <- searchterm %>% 
    str_split(., " AND | OR ") %>% 
    .[[1]] %>% 
    str_remove_all(., "[\\(\\)\"]") %>% 
    map_chr(., str_squish) %>% 
    str_c(., collapse = "|") %>% 
    paste0("(",.,")")
  
  filterterm <- searchterm %>% 
    str_remove_all(., "\"") %>% 
    str_replace_all(., (terms), "grepl(\"\\1\", ., ignore.case = T)") %>% 
    str_replace_all(., " AND ", " & ") %>% 
    str_replace_all(., " OR ", " | ") 
  
  return(filterterm)
  
}

#' Pick out nodes from xml and turn it into a tibble
#' 
#' @param xmlnode an xml node containing nodes
#' @param nodenames the names of the nodes you wish to extract (string with nodes separated by commas)
#' @import dplyr
#' @import tidyr
#' @importFrom xml2 xml_text xml_name
#' @return A tibble with node names as col names and node text as values
#'  

xml2tib <- function(xmlnode, nodenames) {
  
  values <- xmlnode  %>%
    xml_nodes(nodenames) %>% 
    xml2::xml_text() %>% 
    as_tibble()
  
  fields <- xmlnode %>% 
    xml_nodes(nodenames) %>% 
    xml_name() %>% 
    as_tibble() %>% 
    rename(field = value)
  
  bind_cols(values, fields) %>% 
    group_by(field) %>% 
    mutate(value = paste0(value, collapse = " ; ")) %>% 
    unique() %>% 
    ungroup() 
  
}
  
# Pubmed

#' Generates URL for pubmed API
#'
#' @param searchterm text of the query
#' @param startdate from date appeared online (default = 1 year ago today), format YYYY/MM/DD
#' @param enddate to date appeared online (default = today), format YYYY/MM/DD
#' @import dplyr
#' @import stringr
#' @return A URL to search pubmed for a particular term between two given dates
#' 
gen_url_pm <- function(searchterm, 
                         startdate=as.character(Sys.Date()-365, "%Y/%m/%d"), 
                         enddate=as.character(Sys.Date(), "%Y/%m/%d")) {
  
  baseurl <- "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"
  
  term <- searchterm %>% 
    str_replace_all(., "(\")([^\" ]+)( )([^\" ]+)(\")", "%22\\2+\\4%22") %>% 
    str_replace_all(., "(\\))", " \\1") %>%
    paste0(., " ") %>% 
    str_replace_all(., " ", "[tiab] ") %>% 
    str_replace_all(., fixed("AND[tiab]"), "AND") %>% 
    str_replace_all(., fixed("OR[tiab]"), "OR") %>% 
    str_replace_all(., fixed("NOT[tiab]"), "NOT") %>% 
    str_replace_all(., fixed(")[tiab]"), ")") %>% 
    str_squish() %>% 
    str_replace_all(., " ", "+")
  
  searchurl <- paste0(baseurl,
                      "db=pubmed&term=",term,
                      "&datetype=pdat&mindate=",startdate,"&maxdate=",enddate,
                      "&usehistory=y")
  return(searchurl)
}

#' Pubmed search
#' 
#' @param searchurl search URL generated by gen_url_pm()
#' @import httr
#' @importFrom rvest xml_nodes
#' @importFrom xml2 xml_text
#' @return A list with the total hits and history parameters for returning article info
#' 
search_pm <- function(searchurl) {
  
  keyenv <- GET(searchurl) %>%
    content() %>%
    xml_nodes("Count, QueryKey, WebEnv") %>%
    xml2::xml_text()
  
  return(list(count = keyenv[1], querykey = keyenv[2], webenv = keyenv[3]))
  
}

#' Pubmed fetch one page (up to 500 refs) from search
#' 
#' @param pagenumber number of page to retrieve
#' @param historyinfo web environment info returned from search_pm()
#' @import dplyr
#' @import purrr
#' @import tidyr
#' @import httr
#' @importFrom rvest xml_nodes
#' @importFrom xml2 xml_text xml_name
#' @return tibble with info fields on up to 500 articles
#' 
fetch_pm <- function(pagenumber, historyinfo) {
  
  url <- paste0("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&query_key=",
                historyinfo$querykey,"&WebEnv=",historyinfo$webenv,"&retmax=500&retstart=",pagenumber,"&retmode=xml")
  
  articlexml <- GET(url) %>% content() %>% xml_nodes("PubmedArticle")

  articleinfo <- map_df(articlexml, function(x) xml2tib(x, "ArticleTitle, 
                              Abstract, 
                              ArticleId[IdType=\"doi\"], 
                              Journal Title, 
                              PublicationStatus, 
                              PublicationType, 
                              PubDate Year,
                              PubDate Month,
                              PubDate Day,
                              Author LastName")  %>% spread(field, value))
  
  return(articleinfo)
}

#' Pubmed all steps
#' 
#' @param searchterm text of the query
#' @param startdate from date appeared online (default = 1 year ago today), format YYYY/MM/DD
#' @param enddate to date appeared online (default = today), format YYYY/MM/DD
#' @return a tibble of results (8 cols if articles present, 0 if not)
#' 
get_pm <- function(searchterm, 
                   startdate=as.character(Sys.Date()-365, "%Y/%m/%d"), 
                   enddate=as.character(Sys.Date(), "%Y/%m/%d")) {
  
  url <- gen_url_pm(searchterm, startdate, enddate)

  search <- search_pm(url)
  
  if(as.numeric(search$count) > 0) {

    pages <- seq(0, as.numeric(search$count), 500)
  
    results <- map_df(pages, fetch_pm, search) %>% 
      filter(!is.na(Year)) %>% 
      mutate_at(vars(Day, Month), ~if_else(is.na(.), "01", .)) %>% 
      mutate(Month = case_when(
        Month == "Jan" ~ "01",
        Month == "Feb" ~ "01",
        Month == "Mar" ~ "01",
        Month == "Apr" ~ "04",
        Month == "May" ~ "01",
        Month == "Jun" ~ "01",
        Month == "Jul" ~ "01",
        Month == "Aug" ~ "01",
        Month == "Sep" ~ "01",
        Month == "Oct" ~ "01",
        Month == "Nov" ~ "01",
        Month == "Dec" ~ "01",
        TRUE ~ Month
    )) %>% 
      mutate(pdate = paste0(Year,"-",Month,"-",Day)) %>% 
      select(doi = ArticleId,
             title = ArticleTitle,
             abstract = Abstract,
             author = LastName,
             `publication date` = pdate,
             `publication type` = PublicationType,
             `publication status` = PublicationStatus,
             journal = Title)
  
  } else {
    
    results <- tibble()
    
  }
  
  return(results)
  
}

#' Make URL for Springer API
#' 
#' @param searchterm text of query
#' @param datefrom earliest date added
#' @param dateto latest date added
#' @param apikey Springer API key
#' @import stringr
#' 
gen_url_springer <- function(searchterm,
                             datefrom = as.character(Sys.Date() - 365),
                             dateto = as.character(Sys.Date()),
                             apikey) {
  
  baseurl <- "http://api.springernature.com/meta/v2/json?"

  term <- stringr::str_replace_all(stringr::str_replace_all(searchterm, "\"", "%22"), " ", "+")
  
  searchurl <- paste0(baseurl,
                      "q=",term,"+onlinedatefrom:",datefrom,"+onlinedateto:",dateto,
                      "&api_key=",apikey)
  return(searchurl)
}

#' Fetch results from Springer API
#' 
#' @param searchurl URL with the search query
#' @param searchterm original search term (for final filtering)
#' @import dplyr
#' @importFrom jsonlite fromJSON
#' @import purrr
#' @import httr
#' 
get_results_springer <- function(searchurl, searchterm) {
  
  total <- GET(searchurl) %>% 
    content(., "text") %>% 
    fromJSON() %>% 
    .$result %>% .$total 
  
  # paginate
  
  pages <- seq(1, total, 100)
  
  # define function to fetch info from a page
  
  getresults <- function(page, searchurl) {
    
    url <- paste0(searchurl,"&p=100&s=",page)
    
    GET(url) %>% 
      content(., "text") %>% 
      fromJSON() %>% 
      .$records %>% 
      as_tibble() %>% 
      select(doi, title, abstract)
  }
  
  # map across pages
  
  result <- map_df(pages, getresults, searchurl = searchurl)
  
  # filter to articles with desired terms in title and abstract
  
  filterbysearch <- function(searchterm, data) {
    
    filterterm <- search2filter(searchterm)
    
    func_call <- rlang::parse_expr(filterterm)
    
    data %>% 
      filter_at(vars(title, abstract), any_vars(!!func_call))
    
  }

  fresult <- filterbysearch(searchterm, result)
  
  return(fresult)
  
}



